# ==================== Wellbore AI Agent - Environment Configuration ====================
# Copy this file to .env and configure required settings
#
# Required settings are marked with [REQUIRED]
# Optional settings have defaults and are marked with [OPTIONAL]
#
# NEVER commit .env to version control!

# ==================== Application Settings [OPTIONAL] ====================
# These have sensible defaults but can be customized
# DEBUG=true
# HOST="0.0.0.0"
# PORT=8000
# LOG_LEVEL="INFO"

# CORS Origins (comma-separated) - defaults to localhost:3000 and :5173
# CORS_ORIGINS="http://localhost:3000,http://localhost:5173"

# ==================== File Storage [OPTIONAL] ====================
# Base directory for all data (relative to backend root)
# DATA_DIR="data"

# Maximum upload size in bytes (default: 50MB)
# MAX_UPLOAD_SIZE=52428800

# ==================== LLM Configuration (Ollama) [REQUIRED] ====================
# Ollama server URL - MUST be set
OLLAMA_BASE_URL="http://localhost:11434"

# Model to use - MUST be pulled in Ollama first
# Run: ollama pull phi3:mini
OLLAMA_MODEL="phi3:3.8b-mini-4k-instruct-q4_K_M"

# Optional LLM parameters (have defaults)
# OLLAMA_TIMEOUT=120
# LLM_TEMPERATURE=0.1
# LLM_MAX_TOKENS=2048
# LLM_TOP_P=0.9

# ==================== Embedding Configuration [REQUIRED] ====================
# Sentence transformer model for embeddings - MUST be set
HF_TOKEN=YOUR-HUGGING-FACE-TOKEN
EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
RERANKER_MODEL="BAAI/bge-reranker-base"
# Optional embedding parameters
# EMBEDDING_DIMENSION=384  # Must match your model
# EMBEDDING_DEVICE="cpu"

# ==================== Vector Store (ChromaDB) [OPTIONAL] ====================
# Collection name and retrieval settings have defaults
# CHROMA_COLLECTION_NAME="wellbore_documents"
# CHROMA_DISTANCE_METRIC="cosine"
# RETRIEVAL_TOP_K=10
# RETRIEVAL_SCORE_THRESHOLD=0.5

# ==================== Document Processing [OPTIONAL] ====================
# Text chunking - defaults provided
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200

# PDF processing flags
# PDF_EXTRACT_IMAGES=true
# PDF_EXTRACT_TABLES=true

# ==================== Agent Configuration [OPTIONAL] ====================
# MAX_AGENT_ITERATIONS=5
# AGENT_STREAMING=true


# ==================== Performance Settings [OPTIONAL] ====================
# Maximum concurrent LLM requests (for 16GB RAM constraint)
# MAX_CONCURRENT_REQUESTS=3

# WebSocket settings
# WS_HEARTBEAT_INTERVAL=30
# WS_MESSAGE_QUEUE_SIZE=100

# ==================== Quick Start Minimal Config ====================
# For a quick start, you only need these 4 lines:
#
# OLLAMA_BASE_URL="http://localhost:11434"
# OLLAMA_MODEL="phi3:mini"
# EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
# NODAL_API_URL="http://localhost:8001/api/nodal-analysis"
# HF_TOKEN=YOUR-HUGGING-FACE-TOKEN
# Everything else has sensible defaults!